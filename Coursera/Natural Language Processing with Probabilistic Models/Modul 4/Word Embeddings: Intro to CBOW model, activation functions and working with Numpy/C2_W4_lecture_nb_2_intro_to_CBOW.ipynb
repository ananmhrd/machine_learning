{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ananmhrd/machine_learning/blob/main/Coursera/Natural%20Language%20Processing%20with%20Probabilistic%20Models/Modul%204/Word%20Embeddings%3A%20Intro%20to%20CBOW%20model%2C%20activation%20functions%20and%20working%20with%20Numpy/C2_W4_lecture_nb_2_intro_to_CBOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qlcBmOw9J29"
      },
      "source": [
        "# Word Embeddings: Intro to CBOW model, activation functions and working with Numpy\n",
        "\n",
        "In this lecture notebook you will be given an introduction to the continuous bag-of-words model, its activation functions and some considerations when working with Numpy.\n",
        "\n",
        "Let's dive into it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DX0OFJWL9J3C"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip_NRQ6N9J3F"
      },
      "source": [
        "# The continuous bag-of-words model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTQGWTfE9J3F"
      },
      "source": [
        "The CBOW model is based on a neural network, the architecture of which looks like the figure below, as you'll recall from the lecture.\n",
        "\n",
        "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='https://drive.google.com/uc?export=view&id=1blcFy7MYMuBC92scDqmALfTT4vGksxTY' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:917;height:337;\" /> Figure 1 </div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UBZ1XxI9J3G"
      },
      "source": [
        "## Activation functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYL1VArw9J3G"
      },
      "source": [
        "Let's start by implementing the activation functions, ReLU and softmax."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goLPA3Cw9J3G"
      },
      "source": [
        "### ReLU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tCUcRwe9J3H"
      },
      "source": [
        "ReLU is used to calculate the values of the hidden layer, in the following formulas:\n",
        "\n",
        "\\begin{align}\n",
        " \\mathbf{z_1} &= \\mathbf{W_1}\\mathbf{x} + \\mathbf{b_1}  \\tag{1} \\\\\n",
        " \\mathbf{h} &= \\mathrm{ReLU}(\\mathbf{z_1})  \\tag{2} \\\\\n",
        "\\end{align}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vgdh47na9J3H"
      },
      "source": [
        "Let's fix a value for $\\mathbf{z_1}$ as a working example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11leULF79J3I",
        "outputId": "6784b12e-568f-4ca1-8de9-e58354cce155"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.71320643],\n",
              "       [-4.79248051],\n",
              "       [ 1.33648235],\n",
              "       [ 2.48803883],\n",
              "       [-0.01492988]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Define a random seed so all random outcomes can be reproduced\n",
        "np.random.seed(10)\n",
        "\n",
        "# Define a 5X1 column vector using numpy\n",
        "z_1 = 10*np.random.rand(5, 1)-5\n",
        "\n",
        "# Print the vector\n",
        "z_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HBSrZL89J3I"
      },
      "source": [
        "Notice that using numpy's `random.rand` function returns a numpy array filled with values taken from a uniform distribution over [0, 1). Numpy allows vectorization so each value is multiplied by 10 and then substracted 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNfveahZ9J3J"
      },
      "source": [
        "To get the ReLU of this vector, you want all the negative values to become zeros.\n",
        "\n",
        "First create a copy of this vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sxnw035z9J3K"
      },
      "outputs": [],
      "source": [
        "# Create copy of vector and save it in the 'h' variable\n",
        "h = z_1.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rx9QjIF9J3K"
      },
      "source": [
        "Now determine which of its values are negative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jcnRaSf9J3K",
        "outputId": "d986e2a3-6726-4389-fc5d-a0e3bb0c0469"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Determine which values met the criteria (this is possible because of vectorization)\n",
        "h < 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y8hCX-D9J3L"
      },
      "source": [
        "You can now simply set all of the values which are negative to 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SE2-Aez09J3L"
      },
      "outputs": [],
      "source": [
        "# Slice the array or vector. This is the same as applying ReLU to it\n",
        "h[h < 0] = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y6BAW_w9J3M"
      },
      "source": [
        "And that's it: you have the ReLU of $\\mathbf{z_1}$!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E72qo9Is9J3M",
        "outputId": "ef4840c3-2c15-4596-ad32-cf4262a05ee4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.71320643],\n",
              "       [0.        ],\n",
              "       [1.33648235],\n",
              "       [2.48803883],\n",
              "       [0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Print the vector after ReLU\n",
        "h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry_PiUpG9J3M"
      },
      "source": [
        "**Now implement ReLU as a function.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YQAxVg-09J3N"
      },
      "outputs": [],
      "source": [
        "# Define the 'relu' function that will include the steps previously seen\n",
        "def relu(z):\n",
        "    result = z.copy()\n",
        "    result[result < 0] = 0\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y38vbrt49J3N"
      },
      "source": [
        "**And check that it's working.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdfjlor69J3N",
        "outputId": "816d7273-ad28-45bc-c147-bd910c5f129c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        ],\n",
              "       [4.50714306],\n",
              "       [2.31993942],\n",
              "       [0.98658484],\n",
              "       [0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Define a new vector and save it in the 'z' variable\n",
        "z = np.array([[-1.25459881], [ 4.50714306], [ 2.31993942], [ 0.98658484], [-3.4398136 ]])\n",
        "\n",
        "# Apply ReLU to it\n",
        "relu(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ve4_-n3b9J3O"
      },
      "source": [
        "Expected output:\n",
        "\n",
        "    array([[0.        ],\n",
        "           [4.50714306],\n",
        "           [2.31993942],\n",
        "           [0.98658484],\n",
        "           [0.        ]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9fKB40x9J3O"
      },
      "source": [
        "### Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uwzz7M29J3P"
      },
      "source": [
        "The second activation function that you need is softmax. This function is used to calculate the values of the output layer of the neural network, using the following formulas:\n",
        "\n",
        "\\begin{align}\n",
        " \\mathbf{z_2} &= \\mathbf{W_2}\\mathbf{h} + \\mathbf{b_2}   \\tag{3} \\\\\n",
        " \\mathbf{\\hat y} &= \\mathrm{softmax}(\\mathbf{z_2})   \\tag{4} \\\\\n",
        "\\end{align}\n",
        "\n",
        "To calculate softmax of a vector $\\mathbf{z}$, the $i$-th component of the resulting vector is given by:\n",
        "\n",
        "$$ \\textrm{softmax}(\\textbf{z})_i = \\frac{e^{z_i} }{\\sum\\limits_{j=1}^{V} e^{z_j} }  \\tag{5} $$\n",
        "\n",
        "Let's work through an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yaYrrnA9J3P",
        "outputId": "25c575ef-3f2f-4149-d617-6536c2ae1c9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9. ,  8. , 11. , 10. ,  8.5])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Define a new vector and save it in the 'z' variable\n",
        "z = np.array([9, 8, 11, 10, 8.5])\n",
        "\n",
        "# Print the vector\n",
        "z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs4kj_ff9J3Q"
      },
      "source": [
        "You'll need to calculate the exponentials of each element, both for the numerator and for the denominator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkcIlbYt9J3Q",
        "outputId": "ff822448-aa5d-4c50-983c-a94fae52c304"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8103.08392758,  2980.95798704, 59874.1417152 , 22026.46579481,\n",
              "        4914.7688403 ])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Save exponentials of the values in a new vector\n",
        "e_z = np.exp(z)\n",
        "\n",
        "# Print the vector with the exponential values\n",
        "e_z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wng5X3i9J3Q"
      },
      "source": [
        "The denominator is equal to the sum of these exponentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Sg_3lzT9J3R",
        "outputId": "82bb7235-a4b9-42d0-d3e7-d07cfc10dfe3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97899.41826492078"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Save the sum of the exponentials\n",
        "sum_e_z = np.sum(e_z)\n",
        "\n",
        "# Print sum of exponentials\n",
        "sum_e_z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RteapIJr9J3R"
      },
      "source": [
        "And the value of the first element of $\\textrm{softmax}(\\textbf{z})$ is given by:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVbexoUD9J3S",
        "outputId": "6cd1b09d-ed08-4762-fef7-1e479a7777cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08276947985173956"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Print softmax value of the first element in the original vector\n",
        "e_z[0]/sum_e_z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ixO_d4r9J3S"
      },
      "source": [
        "This is for one element. You can use numpy's vectorized operations to calculate the values of all the elements of the $\\textrm{softmax}(\\textbf{z})$ vector in one go.\n",
        "\n",
        "**Implement the softmax function.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "X3vRWVwZ9J3T"
      },
      "outputs": [],
      "source": [
        "# Define the 'softmax' function that will include the steps previously seen\n",
        "def softmax(z):\n",
        "    e_z = np.exp(z)\n",
        "    sum_e_z = np.sum(e_z)\n",
        "    return e_z / sum_e_z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPazopoP9J3T"
      },
      "source": [
        "**Now check that it works.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4g_lsnP9J3U",
        "outputId": "dc7190f2-d4b1-4c09-d419-164e42fb7679"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.08276948, 0.03044919, 0.61158833, 0.22499077, 0.05020223])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Print softmax values for original vector\n",
        "softmax([9, 8, 11, 10, 8.5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G77rwr5O9J3U"
      },
      "source": [
        "Expected output:\n",
        "\n",
        "    array([0.08276948, 0.03044919, 0.61158833, 0.22499077, 0.05020223])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5qIARl69J3U"
      },
      "source": [
        "Notice that the sum of all these values is equal to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTtF6zxe9J3f",
        "outputId": "101a1fc8-8505-4e13-b67b-4a8e79a9fd24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Assert that the sum of the softmax values is equal to 1\n",
        "np.sum(softmax([9, 8, 11, 10, 8.5])) == 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRpZUKY59J3f"
      },
      "source": [
        "## Dimensions: 1-D arrays vs 2-D column vectors\n",
        "\n",
        "Before moving on to implement forward propagation, backpropagation, and gradient descent in the next lecture notebook, let's have a look at the dimensions of the vectors you've been handling until now.\n",
        "\n",
        "Create a vector of length $V$ filled with zeros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tvJJMAB9J3g",
        "outputId": "058def67-da28-4a80-b9d0-a2e8f82db67f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Define V. Remember this was the size of the vocabulary in the previous lecture notebook\n",
        "V = 5\n",
        "\n",
        "# Define vector of length V filled with zeros\n",
        "x_array = np.zeros(V)\n",
        "\n",
        "# Print vector\n",
        "x_array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y-ddfml9J3g"
      },
      "source": [
        "This is a 1-dimensional array, as revealed by the `.shape` property of the array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtBpy_Ix9J3h",
        "outputId": "05567310-2f01-436f-e99f-8b26a6df7d94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Print vector's shape\n",
        "x_array.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW-LtbER9J3i"
      },
      "source": [
        "To perform matrix multiplication in the next steps, you actually need your column vectors to be represented as a matrix with one column. In numpy, this matrix is represented as a 2-dimensional array.\n",
        "\n",
        "The easiest way to convert a 1D vector to a 2D column matrix is to set its `.shape` property to the number of rows and one column, as shown in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM1Vgnyb9J3i",
        "outputId": "31f79ce3-457d-4f03-c0a3-06813769fe3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Copy vector\n",
        "x_column_vector = x_array.copy()\n",
        "\n",
        "# Reshape copy of vector\n",
        "x_column_vector.shape = (V, 1)  # alternatively ... = (x_array.shape[0], 1)\n",
        "\n",
        "# Print vector\n",
        "x_column_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54zm7vQ49J3j"
      },
      "source": [
        "The shape of the resulting \"vector\" is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlRj_I2v9J3j",
        "outputId": "1abf2671-978a-4aa5-8b19-bb02eaa7dcb5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Print vector's shape\n",
        "x_column_vector.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-Xa4mTq9J3k"
      },
      "source": [
        "So you now have a 5x1 matrix that you can use to perform standard matrix multiplication."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg4xNsdv9J3k"
      },
      "source": [
        "**Congratulations on finishing this lecture notebook!** Hopefully you now have a better understanding of the activation functions used in the continuous bag-of-words model, as well as a clearer idea of how to leverage Numpy's power for these types of mathematical computations.\n",
        "\n",
        "In the next lecture notebook you will get a comprehensive dive into:\n",
        "\n",
        "- Forward propagation.\n",
        "\n",
        "- Cross-entropy loss.\n",
        "\n",
        "- Backpropagation.\n",
        "\n",
        "- Gradient descent.\n",
        "\n",
        "**See you next time!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}